{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Wizards!\n",
    "\n",
    "## Instructors: Shervin Manzuri, Levin Noronha, Morteza Alipour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction! \n",
    "\n",
    "This is going to be your first venture into **DATA SCIENCE**! Data science is the cool job of doing magic with piles of stuff most people don't understand!\n",
    "\n",
    "A data scientist is basically a **wizard**! These wizards will get certain ingredients in the forms of **RAW Data** and they will make them into an **easily digestable data potion**! Then using **magic** they will predict the future! However before you become magicians you will first need to improve your **Cooking** skill!\n",
    "\n",
    "## What potion we are making?\n",
    "\n",
    "We want to look at **DC** and **Marvel** comic characters and do data science wizardry with them! So our ingredients will be their data.\n",
    "\n",
    "What does a good cook usually do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fetching the Ingredients\n",
    "\n",
    "As a data scientist wizard, you first need to gather your **necessary ingredients**. Wizards use herbs and water to make potions! But data scientist wizards use... wait for it... **DATA**. Just as a good potion needs quality herbs, good data scientists need to carefully choose their data. If they use bad data, they might create **poisonous potions**! We really don't want poison now do we? \n",
    "\n",
    "Now the question is...\n",
    "\n",
    "### 1.1. How do we choose the data?\n",
    "\n",
    "The first rule of thumb for wizards when picking quality herbs is they must be **clean**, **fresh** and without **pests**! \n",
    "\n",
    "Well you guessed it, it's exactly the same case for data scientist wizards. Because we *are* wizards.\n",
    "\n",
    "Your first job as a data scientist wizard is to **pick and clean your ingredients**! LET'S GO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing\n",
    "\n",
    "The first step when writing python magic is importing your tools! We will do this for you. The tools we will import are two friendly neighborhood sidekicks named *pandas*, *numpy* and their projector device that is called *matplotlib*. We will call upon *pandas* and *numpy* to help us later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching our Ingredients\n",
    "\n",
    "Now we need python, our sidekick to fetch (read) the ingredients we want to clean! We need to tell it the address of where to find the ingredient! Both our ingredients are in our computer so we need to tell it the local address!\n",
    "\n",
    "The name of the datasets are:\n",
    "\n",
    "    1- heroes_information.csv\n",
    "    2- super_hero_powers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our First ingredient!\n",
    "heroes_info = pd.read_csv( ? ,index_col = 0)\n",
    "#Our second ingredient!\n",
    "superhero_powers = pd.read_csv( ? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have our ingredients...\n",
    "\n",
    "We need to see how much of each we have, our ingredients come in packages and they can be of different types, shapes, lengths, *smells* or even tastes.\n",
    "\n",
    "To explore our data ingredients we can ask our friend *pandas* to **describe** them for us. We have to ask him separately for each ingredient as **pandas are lazy**!\n",
    "\n",
    "#### Let's ask pandas to show us 5 pieces of our first ingredient, **superhero powers**:\n",
    "\n",
    "To do this we call the head function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superhero_powers. ? ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's ask pandas to show us 6 pieces of our second ingredient, **superhero info**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heroes_info.head( ? )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Cleaning our ingredients\n",
    "\n",
    "Now that we have seen what our ingredients look like, we need to clean them up! Now when we want to clean up food ingredients we look for dirty parts, stale parts or parts that don't make sense (we don't want to put nails in our soup!).\n",
    "\n",
    "The same goes for **data cleaning**. When we want to clean our data ingredients, we will look for:\n",
    "\n",
    "    1. Data rows that don't make sense.\n",
    "    2. Data rows that look wrong, but otherwise we can use them.\n",
    "    3. Data we don't think we will need.\n",
    "    \n",
    "Now looking at the tables above, which ones do you think don't make sense? Which ones we need but need to change how they look? and which ones we won't need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Don't look ahead! We need your expertise first!\n",
    "\n",
    "## 2.1.1 You haven't been looking ahead now have you?\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Now that you have some insight, let's see what needs to be cleaned!\n",
    "\n",
    "We don't want problems of type 1 and 2 affect our analysis.\n",
    "\n",
    "    1. Do you think a height of -99 or weight of -99 makes sense?\n",
    "    2. We need to let python know if we don't have information about something. Otherwise it wouldn't know what to do! The way we do this is by turning cells with \"-\" into \"NA\" (not a number).\n",
    "    this is done using np.nan.\n",
    "    \n",
    "And we want to drop certain values!\n",
    "\n",
    "    3. We want to compare Marvel to DC! So we need to drop all heroes that don't belong to them.\n",
    "    \n",
    "#### Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing -99 height to NA\n",
    "heroes_info.loc[heroes_info[ ? ] < 0, ? ] = ? #set incorrect heights to nan\n",
    "heroes_info.loc[heroes_info[ ? ] < 0, ? ] = ? #set incorrect weights to nan\n",
    "\n",
    "# Changing - to NA\n",
    "superhero_powers = superhero_powers.replace( ? , np.nan) #Do you know why we put the semicolon here? remove it and see!\n",
    "heroes_info = heroes_info.replace( ? , np.nan)\n",
    "\n",
    "# Dropping non Marvel and non DC\n",
    "superhero_powers = superhero_powers.rename(columns ={ ? : ? }) #we have two column names that are different but are showing the same thing!\n",
    "merged_data = pd.merge(heroes_info, superhero_powers, on= ? ) # what is the same column in both now?\n",
    "\n",
    "dc_data = merged_data.drop(merged_data.loc[(merged_data[ ? ]!='DC Comics')].index)\n",
    "marvel_data = merged_data.drop(merged_data.loc[(merged_data[ ? ]!='Marvel Comics')].index)\n",
    "mdc_data = pd.concat([dc_data, marvel_data], axis=0).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's display our cleaned data!\n",
    "\n",
    "Use the display() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ? (mdc_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Let's Analyse the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our ingredients cleaned up we can start looking at how they would cook together. As a data scientist wizard you have to look at data to find interesting insights. Sometimes this data is already cleaned up and sometimes you have to clean it up.\n",
    "\n",
    "By looking at how small parts in your data are related to each other, you can start making educated guesses about how they work or how their behaviour can be predicted. Which is basically **magic**. We want to look at our cleaned data from different perspectives, look at how they're distributed and the insteresting insights we can learn from that.\n",
    "\n",
    "### 3.1. Distribution Analysis\n",
    "\n",
    "Data distribution is the most important part of a wizard's job. The distribution of our data parts can help us with predicting the future.\n",
    "\n",
    "Our data contains rows and columns, each row is a **sample** and each column is a **feature**. Most of the time we compare the distributions of two features because we have samples to create our distribution shape! The shape of our distribution is also called its **probability density function**.\n",
    "\n",
    "Now without going into the boring math (or amazingly beatiful math) of this thing, we will do an easier explanation. We show the distribution using **histograms**. a Histogram is like having many buckets, and every time you see a new sample, you put it into the correct bucket where only specific numbers can go in.\n",
    "\n",
    "Now to draw the histograms, our samples must be of **numerical type**! This means we can only use numbers! \n",
    "\n",
    "Let's draw some histograms! One interesting thing to do would be comparing the distributions of some features! You choose!\n",
    "\n",
    "#### Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_hist_input = mdc_data.loc[(mdc_data[ ?Attribute ] == ?Value ), ?2ndAttribute]\n",
    "second_hist_input = mdc_data.loc[(mdc_data[ ?Attribute ] == ?Value ), ?2ndAttribute]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have chosen our features to compare, we draw the histogram! Two things you can play with:\n",
    "\n",
    "    1- Number of buckets for each histogram: between 10-1000\n",
    "    2- The limits of our plot: plt.xlim(beginning, end)\n",
    "    \n",
    "#### Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_histogram_buckets = 300 #you can change this\n",
    "second_histogram_buckets = 100 #you can change this too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(first_hist_input, first_histogram_buckets, alpha=0.5, label='Male')\n",
    "plt.hist(second_hist_input, second_histogram_buckets, alpha=0.5, label='Female')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Height Distribution of heroes!')\n",
    "plt.xlabel('Height')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "\n",
    "plt.xlim(50,210) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Frequency Analysis\n",
    "\n",
    "Now we're going to look at our heroes and see which features happen more frequently in them! Our idea is, some superpowers are more abundant than others! So heroes with these superpowers won't be very unique! Let's try to find what are the most **common** super powers that heroes have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How do we count the superpowers?\n",
    "\n",
    "We need to go through our superpowers and count the number of times they appear in any hero! Then we will sum them up and extract the top 20 most common super powers both in the Marvel and the DC universe, then we will see how they relate to each other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_dic_dc = {}\n",
    "for column in dc_data.columns[10:]:\n",
    "    pf_dic_dc[column] = sum(dc_data[column])\n",
    "    \n",
    "pf_dic_mar = {}\n",
    "for column in marvel_data.columns[10:]:\n",
    "    pf_dic_mar[column] = sum(marvel_data[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_twenty_mar = dict(Counter(pf_dic_mar).most_common( ? ))\n",
    "max_twenty_dc = dict(Counter(pf_dic_dc).most_common( ? ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have our top 20 most common super powers for each universe, we will combine them into one table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max20_mar_data = pd.DataFrame({'Power':list(max_twenty_mar.keys()),'Frequency':list(max_twenty_mar.values()), 'Publisher':['Marvel']*20})\n",
    "max20_dc_data = pd.DataFrame({'Power':list(max_twenty_dc.keys()),'Frequency':list(max_twenty_dc.values()), 'Publisher':['DC']*20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_powers = pd.concat([ ? , ? ] , axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we will draw a Horizontal bar plot! \n",
    "\n",
    "a Horizontal bar plot is really cool! It stacks the number of times we see something and then can differentiate between each universe! Just wait and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"#006D2C\", \"#31A354\",\"#74C476\"]\n",
    "pivot_df = pd.pivot_table(max_powers,index='Power', columns='Publisher', values='Frequency', fill_value=0)\n",
    "pivot_df = pivot_df.reindex(pivot_df.sort_values(by='DC', ascending=True).index)\n",
    "pivot_df = pivot_df.reindex(pivot_df.sort_values(by='Marvel', ascending=True).index)\n",
    "\n",
    "pivot_df.plot.barh(stacked=True, color=colors, figsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Bad Guy Analysis\n",
    "\n",
    "Now let's look at Marvel and DC. Which universe do you think has more **bad** heroes compared to good heroes?\n",
    "\n",
    "\n",
    "#### How do we know who's good or bad?\n",
    "\n",
    "Do we need to look at each superhero and read all their comics in order to judge whether their character is good or bad? Well, we could do that but that would take a very long time! And as data wizards, why should we waste time doing repetitive manual tasks when we can perform some data wizardry on the vast amounts of data we already have available. So let's go ahead and look through our superhero data to examine which side they align with - good or evil!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "r = [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Marvel data\n",
    "marvel_alignment = mdc_data.loc[(mdc_data['Publisher'] == ?publisherValue ), ?superheroCharacteristic ].value_counts()\n",
    "marvel_alignment_dict = marvel_alignment.to_dict()\n",
    "# Get DC data\n",
    "dc_alignment = mdc_data.loc[(mdc_data['Publisher'] == ?publisherValue ), ?superheroCharacteristic ].value_counts()\n",
    "dc_alignment_dict = dc_alignment.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_alignment_dict = {}\n",
    "# Combine Marvel and DC data\n",
    "if marvel_alignment_dict.keys() == dc_alignment_dict.keys():\n",
    "    for key in marvel_alignment_dict:\n",
    "        combined_alignment_dict[key] = [marvel_alignment_dict[key], dc_alignment_dict[key]]\n",
    "df = pd.DataFrame(combined_alignment_dict, index=['Marvel', 'DC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the superhero alignment information in our hands, let's go forth and turn our data into percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From raw value to percentage\n",
    "totals = [i+j+k for i,j,k in zip(df['good'], df['bad'], df['neutral'])]\n",
    "goodBars = [i / j for i,j in zip(df['good'], totals)]\n",
    "neutralBars = [i / j for i,j in zip(df['neutral'], totals)]\n",
    "badBars = [i / j for i,j in zip(df['bad'], totals)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's go ahead and draw that graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "plt.figure(figsize=(8,12))\n",
    "barWidth = 0.85\n",
    "names = ('Marvel','DC')\n",
    "# Create good bars\n",
    "plt.bar(r, goodBars, color='#99ff66', width=barWidth)\n",
    "# Create neutral bars\n",
    "plt.bar(r, neutralBars, bottom=goodBars, color='#3399ff', width=barWidth)\n",
    "# Create blue Bars\n",
    "plt.bar(r, badBars, bottom=[i+j for i,j in zip(goodBars, neutralBars)], color='#ff5050', width=barWidth)\n",
    " \n",
    "# Custom x and y axis\n",
    "plt.xticks(r, names)\n",
    "plt.xlabel(\"Universe\")\n",
    "plt.ylabel('Percentage')\n",
    " \n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "# Legend\n",
    "good_patch = mpatches.Patch(color='#99ff66', label='Good')\n",
    "neutral_path = mpatches.Patch(color='#3399ff', label='Neutral')\n",
    "red_patch = mpatches.Patch(color='#ff5050', label='Bad')\n",
    "plt.legend(handles=[red_patch, neutral_path, good_patch],bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "# Title\n",
    "plt.title('Superhero Alignment by Universe')\n",
    "\n",
    "# Show graphic\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
